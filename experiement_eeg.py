# -*- coding: utf-8 -*-
"""Experiement EEG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kw9snvQR8jDNPDRjSLTO9yX4wvmlsPxx
"""

!pip install sdv==1.4.0

!pip install numpy==1.26.4
!pip install --upgrade tensorflow keras

!pip install scikeras
# importing libraries
import pandas as pd
import numpy as np
from numpy import mean
from numpy import std
from pandas import read_csv
from sklearn.model_selection import LeaveOneOut
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier,StackingClassifier
from sklearn.svm import SVC
from lightgbm import LGBMClassifier
import keras
from time import time
from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score
from keras.models import Sequential
from keras.layers import Dense, Activation, Flatten, Conv1D, Dropout, BatchNormalization, MaxPooling1D, LeakyReLU
from scikeras.wrappers import KerasClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from sdv.metadata import SingleTableMetadata
from sdv.single_table import GaussianCopulaSynthesizer
from sdv.single_table import CTGANSynthesizer
from sdv.single_table import TVAESynthesizer
from sdv.evaluation.single_table import evaluate_quality
from imblearn.over_sampling import ADASYN
from collections import Counter
from imblearn.over_sampling import SMOTE
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#load Data
df=pd.read_csv('/content/dataset-eeg.csv')
df.drop(columns=['Patient_ID','Gender'], axis=1, inplace=True)
# check data information
print("Shape of dataset:", df.shape)
print("\nData Types:")
print(df.dtypes)

print("\nMissing Values:")
print(df.isnull().sum())

print("\nBasic Statistics:")
print(df.describe(include='all'))

#Check for Duplicates
print("\nNumber of duplicate rows:", df.duplicated().sum())

#Correlation Matrix
plt.figure(figsize=(10,6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

#Distribution of Each Numeric Feature
df.hist(figsize=(15,10), bins=30, edgecolor="black")
plt.suptitle("Distribution of Numerical Features")
plt.show()

#Boxplots for Outlier Detection
plt.figure(figsize=(15,8))
df.boxplot()
plt.title("Boxplots for Outlier Detection")
plt.xticks(rotation=90)
plt.show()

# If target column exists
target_col = "Emotion"  # <-- replace with your label column if you have one
if target_col in df.columns:
    print("\nTarget Value Counts:")
    print(df[target_col].value_counts())

    plt.figure(figsize=(6,4))
    sns.countplot(x=target_col, data=df, palette="Set2")
    plt.title("Target Class Distribution")
    plt.show()

    # Feature vs Target distribution
    num_cols = df.select_dtypes(include=np.number).columns
    for col in num_cols:
        if col != target_col:
            plt.figure(figsize=(6,4))
            sns.boxplot(x=target_col, y=col, data=df, palette="Set3")
            plt.title(f"{col} vs {target_col}")
            plt.show()
# Label data for categorical value
le = LabelEncoder()
df['Mind State'] = le.fit_transform(df['Mind State'])

#Generating synthetic data
metadata = SingleTableMetadata()
metadata.detect_from_dataframe(data=df)

synthesizer=CTGANSynthesizer(
    metadata,
    epochs=2000,
    batch_size=500,
    cuda=True,
    embedding_dim=786,
    enforce_min_max_values=True,
    enforce_rounding=False,
)

synthesizer.fit(df)

synthetic_data = synthesizer.sample(num_rows=20000)
frequency_pairs = [
    ('low_Alpha(Hz)', 'high_Alpha(Hz)'),
    ('low_Beta(Hz)', 'high_Beta(Hz)'),
    ('low_Gamma(Hz)', 'high_Gamma(Hz)')
]

for low_col, high_col in frequency_pairs:
    mask = synthetic_data[low_col] > synthetic_data[high_col]
    synthetic_data.loc[mask, [low_col, high_col]] = synthetic_data.loc[mask, [high_col, low_col]].values
# checking data quality of synthetic data with original data
quality_report = evaluate_quality(
    df,
    synthetic_data,
    metadata)

df.describe()

synthetic_data.describe()

synthetic_data=synthetic_data.drop_duplicates()

synthetic_data.shape

synthetic_data['Mind State'].value_counts()

X = df.drop(columns=['Mind State'], axis=1)
y = df['Mind State']

print("Loaded:", X.shape)
print("Target distribution BEFORE:", Counter(y))

adasyn = ADASYN(sampling_strategy='minority', random_state=42)

# Apply ADASYN
X_res_adasyn, y_res_adasyn = adasyn.fit_resample(X, y)

print("After ADASYN sampling shapes:", X_res_adasyn.shape, y_res_adasyn.shape)
print("Target distribution AFTER:", Counter(y_res_adasyn))

# Separate features (X) and target (y) from the original dataframe
X = df.drop(columns=['Mind State'], axis=1)
y = df['Mind State']

print("Loaded:", X.shape)
print("Target distribution BEFORE:", Counter(y))

# Define SMOTE with appropriate parameters
smote = SMOTE(sampling_strategy='auto', random_state=42)

# Apply SMOTE
X_res_smote, y_res_smote = smote.fit_resample(X, y)

print("After SMOTE sampling shapes:", X_res_smote.shape, y_res_smote.shape)
print("Target distribution AFTER:", Counter(y_res_smote))


# Combine ADASYN features and target back into a DataFrame
adasyn_df = pd.DataFrame(X_res_adasyn, columns=X.columns)
adasyn_df['Mind State'] = y_res_adasyn

# Combine SMOTE features and target back into a DataFrame
smote_df = pd.DataFrame(X_res_smote, columns=X.columns)
smote_df['Mind State'] = y_res_smote


# Concatenate all dataframes
merged_df = pd.concat([df, synthetic_data, adasyn_df, smote_df], ignore_index=True)

print("Shape of the merged dataframe:", merged_df.shape)
display(merged_df.head())
display(merged_df['Mind State'].value_counts())

X = merged_df[['low_Alpha(Hz)', 'high_Alpha(Hz)', 'low_Beta(Hz)', 'high_Beta(Hz)', 'low_Gamma(Hz)', 'high_Gamma(Hz)']]
y = merged_df['Mind State']

if y.dtype == 'object':
    le = LabelEncoder()
    y = le.fit_transform(y)
#Splitting the dataset
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.30, stratify=y, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=42)
#applying Cross Validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
# function for 1D CNN parameters
def create_1dcnn():
    model = Sequential()
    model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(6, 1)))
    model.add(Flatten())
    model.add(Dense(64, activation='relu'))
    model.add(Dense(len(np.unique(y)), activation='softmax'))
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model
#Scaling the data
scaler = StandardScaler()
scaler.fit(X_train)

features = X_train.columns
#splitting the data as train, test and validation 
X_train[features] = scaler.transform(X_train)
X_val[features] = scaler.transform(X_val)
X_test[features] = scaler.transform(X_test)

parameters = {
    "C":[0.001,0.01,0.1,1.0,10,100,1000],
    "penalty":["l1","l2","elasticnet",None],
    "solver":["newton-cg","lbfgs","liblinear","sag","saga"],
    "max_iter":[500,1000]
}
#Logistic regression
lr_cv = GridSearchCV(LogisticRegression(), parameters, cv=5)
lr_cv.fit(X_train[features],y_train.values.ravel())

lr = lr_cv.best_estimator_
lr.fit(X_train[features],y_train.values.ravel())

parameters = {
    "criterion":["gini","entropy"],
    "max_depth":[2,4,8,16,32],
    "min_samples_leaf":[2,4,8,16,32],
    "min_samples_split":[2,4,8,16,32]
}
#Decision Tree
dt_cv = GridSearchCV(DecisionTreeClassifier(), parameters, cv=5)
dt_cv.fit(X_train[features],y_train.values.ravel())

dt = dt_cv.best_estimator_
dt.fit(X_train[features],y_train.values.ravel())

parameters = {
    "max_depth":[2,4,8,16,32],
    "n_estimators":[5,50,250,500]
}
#Random Forest
rf_cv = GridSearchCV(RandomForestClassifier(), parameters, cv=5)
rf_cv.fit(X_train[features],y_train.values.ravel())

rf = rf_cv.best_estimator_
rf.fit(X_train[features],y_train.values.ravel())

parameters = {
    "learning_rate":[0.01,0.1,1.0,10,100],
    "n_estimators":[5,50,250,500]
}
#Ada Boost Classifier
ada_cv = GridSearchCV(AdaBoostClassifier(), parameters, cv=5)
ada_cv.fit(X_train[features],y_train.values.ravel())

ada = ada_cv.best_estimator_
ada.fit(X_train[features],y_train.values.ravel())

parameters = {
    "boosting_type":["gbdt","dart","goss","rf"],
    "learning_rate":[0.01,0.1,1.0,10,100],
    "max_depth":[2,4,8,16,32],
    "n_estimators":[5,50,250,500]
}
#Light Gradient Boosting Machine
lgbm_cv = GridSearchCV(LGBMClassifier(), parameters, cv=5)
lgbm_cv.fit(X_train[features],y_train.values.ravel())

lgbm = lgbm_cv.best_estimator_
lgbm.fit(X_train[features],y_train.values.ravel())

parameters = {
    "algorithm":["ball_tree","kd_tree","brute"],
    "metric":["minkowski","euclidean","manhattan"],
    "n_neighbors":range(2,21),
    "weights":["uniform","distance"]
}
# K- nearest neighbour
knn_cv = GridSearchCV(KNeighborsClassifier(), parameters, cv=5)
knn_cv.fit(X_train[features],y_train.values.ravel())

knn = knn_cv.best_estimator_
knn.fit(X_train[features],y_train.values.ravel())

parameters = {
    "C":[0.001,0.01,0.1,1.0,10,100,1000],
    "kernel":["linear","poly","rbf","sigmoid"]
}
#Support Vector Machine
svc_cv = GridSearchCV(SVC(), parameters, cv=5)
svc_cv.fit(X_train[features],y_train.values.ravel())

svc = svc_cv.best_estimator_
svc.fit(X_train[features],y_train.values.ravel())

parameters = {
    "activation":["identity","logistic","tanh","relu"],
    "hidden_layer_sizes":[(10,),(50,),(100,)],
    "learning_rate":["constant","invscaling","adaptive"],
    "solver":["lbfgs","sgd","adam"]
}
# Multi layer perceptron
mlp_cv = GridSearchCV(MLPClassifier(), parameters, cv=5)
mlp_cv.fit(X_train[features],y_train.values.ravel())

mlp = mlp_cv.best_estimator_
mlp.fit(X_train[features],y_train.values.ravel())

estimators = [("lr",lr),("dt",dt),("rf",rf),("ada",ada),("lgbm",lgbm),("knn",knn),("svc",svc),("mlp",mlp)]
parameters = {
    "passthrough":[True,False]
}
#Grid Search
sc_cv = GridSearchCV(StackingClassifier(estimators=estimators, final_estimator=lr_cv.best_estimator_), parameters, cv=5)
sc_cv.fit(X_train[features],y_train.values.ravel())

sc = sc_cv.best_estimator_
sc.fit(X_train[features],y_train.values.ravel())

models = [lr,dt,rf,ada,lgbm,knn,svc,mlp,sc]
#evaluating traing performance
train_set = pd.DataFrame()

for i in models:
        start = time()
        pred = i.predict(X_train[features])
        end = time()
        temp = pd.DataFrame(
                {
                    "Accuracy":("%0.3f" % (accuracy_score(y_train,pred))),
                    "F1":("%0.3f" % (f1_score(y_train,pred,average='micro'))),
                    "Precision":("%0.3f" % (precision_score(y_train,pred,average='micro'))),
                    "Recall":("%0.3f" % (recall_score(y_train,pred,average='micro'))),
                    "Latency":("%0.1fms" % ((end-start)*1000))
                }, index=[str(i).split("Classifier")[0].split("(")[0]]
        )
        train_set = pd.concat([train_set,temp])
train_set
#Evaluating test performance
test_set = pd.DataFrame()

for i in models:
        start = time()
        pred = i.predict(X_test[features])
        end = time()
        temp = pd.DataFrame(
                {
                    "Accuracy":("%0.3f" % (accuracy_score(y_test,pred))),
                    "F1":("%0.3f" % (f1_score(y_test,pred,average='micro'))),
                    "Precision":("%0.3f" % (precision_score(y_test,pred,average='micro'))),
                    "Recall":("%0.3f" % (recall_score(y_test,pred,average='micro'))),
                    "Latency":("%0.1fms" % ((end-start)*1000))
                }, index=[str(i).split("Classifier")[0].split("(")[0]]
        )
        test_set = pd.concat([test_set,temp])
test_set
#Evaluating validation performance
val_set = pd.DataFrame()

for i in models:
        start = time()
        pred = i.predict(X_val[features])
        end = time()
        temp = pd.DataFrame(
                {
                    "Accuracy":("%0.3f" % (accuracy_score(y_val,pred))),
                    "F1":("%0.3f" % (f1_score(y_val,pred,average='micro'))),
                    "Precision":("%0.3f" % (precision_score(y_val,pred,average='micro'))),
                    "Recall":("%0.3f" % (recall_score(y_val,pred,average='micro'))),
                    "Latency":("%0.1fms" % ((end-start)*1000))
                }, index=[str(i).split("Classifier")[0].split("(")[0]]
        )
        val_set = pd.concat([val_set,temp])
val_set
#Evaluating CNN
X_train_cnn = np.expand_dims(X_train.values, axis=2)
X_val_cnn = np.expand_dims(X_val.values, axis=2)
cnn_model = create_1dcnn()
cnn_model.fit(X_train_cnn, y_train, validation_data=(X_val_cnn, y_val), epochs=2000, batch_size=500)

# Evaluate the CNN model on the training set
loss_train, accuracy_train = cnn_model.evaluate(X_train_cnn, y_train, verbose=0)
print(f"CNN Training Accuracy: {accuracy_train:.3f}")

# Evaluate the CNN model on the validation set
loss_val, accuracy_val = cnn_model.evaluate(X_val_cnn, y_val, verbose=0)
print(f"CNN Validation Accuracy: {accuracy_val:.3f}")

# Prepare the test data for the CNN model
X_test_cnn = np.expand_dims(X_test.values, axis=2)

# Evaluate the CNN model on the test set
loss_test, accuracy_test = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)
print(f"CNN Test Accuracy: {accuracy_test:.3f}")

for model in models:
    model_name = str(model).split("Classifier")[0].split("(")[0]
    print(f"Generating confusion matrix for {model_name}...")

    if model_name == "Sequential": # Handle the CNN model separately
        # Reshape X_test for the CNN model
        X_test_cnn = np.expand_dims(X_test.values, axis=2)
        y_pred = model.predict(X_test_cnn)
        y_pred_classes = np.argmax(y_pred, axis=1)
    else:
        y_pred = model.predict(X_test[features])
        y_pred_classes = y_pred # For non-CNN models, prediction is already the class

    cm = confusion_matrix(y_test, y_pred_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
    disp.plot()
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()

# Create a bar plot for training accuracy
plt.figure(figsize=(10, 6))
plt.bar(train_set.index, train_set['Accuracy'].astype(float), color='skyblue')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Training Accuracy of Different Models')
plt.ylim(0.8, 1.0)  # Adjust y-axis limits if needed
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Create a bar plot for testing accuracy
plt.figure(figsize=(10, 6))
plt.bar(test_set.index, test_set['Accuracy'].astype(float), color='lightcoral')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Testing Accuracy of Different Models')
plt.ylim(0.8, 1.0)  # Adjust y-axis limits if needed
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Create a bar plot for training accuracy
plt.figure(figsize=(12, 6))
plt.bar(train_set.index, train_set['Accuracy'].astype(float), color='skyblue')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Training Accuracy of Different Models (Including CNN)')
plt.ylim(0.8, 1.0)  # Adjust y-axis limits if needed
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Create a bar plot for testing accuracy
plt.figure(figsize=(12, 6))
plt.bar(test_set.index, test_set['Accuracy'].astype(float), color='lightcoral')
plt.xlabel('Model')
plt.ylabel('Accuracy')
plt.title('Testing Accuracy of Different Models (Including CNN)')
plt.ylim(0.8, 1.0)  # Adjust y-axis limits if needed
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

# Evaluate the CNN model on the training set
loss_train_cnn, accuracy_train_cnn = cnn_model.evaluate(X_train_cnn, y_train, verbose=0)

# Evaluate the CNN model on the test set
loss_test_cnn, accuracy_test_cnn = cnn_model.evaluate(X_test_cnn, y_test, verbose=0)

def to_class_labels(y):
    """Convert y to 1D integer labels if it's one-hot."""
    y = np.asarray(y)
    if y.ndim > 1 and y.shape[-1] > 1:
        return np.argmax(y, axis=1)
    return y.astype(int).ravel()

def predict_classes(model, X):
    """Return 1D class labels from model predictions for binary or multi-class."""
    proba = model.predict(X, verbose=0)
    proba = np.asarray(proba)
    if proba.ndim == 1 or proba.shape[-1] == 1:
        # binary: sigmoid output
        return (proba.ravel() >= 0.5).astype(int)
    else:
        # multi-class: softmax output
        return np.argmax(proba, axis=1)

# 1D labels
y_train_lbl = to_class_labels(y_train)
y_test_lbl  = to_class_labels(y_test)

# predicted labels
y_pred_train = predict_classes(cnn_model, X_train_cnn)
y_pred_test  = predict_classes(cnn_model, X_test_cnn)
prec_train = precision_score(y_train_lbl, y_pred_train, average='weighted', zero_division=0)
rec_train  = recall_score(y_train_lbl, y_pred_train, average='weighted', zero_division=0)
f1_train   = f1_score(y_train_lbl, y_pred_train, average='weighted', zero_division=0)

prec_test = precision_score(y_test_lbl, y_pred_test, average='weighted', zero_division=0)
rec_test  = recall_score(y_test_lbl, y_pred_test, average='weighted', zero_division=0)
f1_test   = f1_score(y_test_lbl, y_pred_test, average='weighted', zero_division=0)

# Add CNN accuracy to train_set
cnn_train_temp = pd.DataFrame(
    {
        "Accuracy": (f"{accuracy_train_cnn:.3f}"),
        "F1":        f"{f1_train:.3f}",
        "Precision": f"{prec_train:.3f}",
        "Recall":    f"{rec_train:.3f}",
    }, index=["Sequential"]
)
train_set = pd.concat([train_set, cnn_train_temp])

# Add CNN accuracy to test_set
cnn_test_temp = pd.DataFrame(
    {
        "Accuracy":  f"{accuracy_test_cnn:.3f}",
        "F1":        f"{f1_test:.3f}",
        "Precision": f"{prec_test:.3f}",
        "Recall":    f"{rec_test:.3f}",
    }, index=["Sequential"]
)
test_set = pd.concat([test_set, cnn_test_temp])

print("Updated Training Set:")
display(train_set)

print("\nUpdated Test Set:")
display(test_set)

epochs = range(1, len(history_cnn.history["accuracy"]) + 1)

# Training accuracy
plt.figure()
plt.plot(epochs, history_cnn.history["accuracy"], marker='o')
plt.title("Training Accuracy vs. Epoch")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

# Test (validation) accuracy
plt.figure()
plt.plot(epochs, history_cnn.history["val_accuracy"], marker='o')
plt.title("Test Accuracy vs. Epoch")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

# warm-up (to avoid first-call overhead)
_ = cnn_model.predict(X_test_cnn[:10], verbose=0)

# measure time for predictions
start = time.time()
_ = cnn_model.predict(X_test_cnn, verbose=0)
end = time.time()

total_time = end - start
n_samples = X_test_cnn.shape[0]

latency_per_sample = total_time / n_samples
print(f"Total inference time: {total_time:.4f} sec")
print(f"Latency per sample: {latency_per_sample*1000:.4f} ms")

if cnn_model not in models:
    models_with_cnn = models + [cnn_model]
else:
    models_with_cnn = models


for model in models_with_cnn:
    model_name = str(model).split("Classifier")[0].split("(")[0]
    print(f"Generating confusion matrix for {model_name}...")

    if model_name == "Sequential": # Handle the CNN model separately
        # Reshape X_test for the CNN model
        X_test_cnn = np.expand_dims(X_test.values, axis=2)
        y_pred = model.predict(X_test_cnn)
        y_pred_classes = np.argmax(y_pred, axis=1)
    else:
        y_pred = model.predict(X_test[features])
        y_pred_classes = y_pred # For non-CNN models, prediction is already the class

    cm = confusion_matrix(y_test, y_pred_classes)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)
    disp.plot()
    plt.title(f'Confusion Matrix for {model_name}')
    plt.show()
